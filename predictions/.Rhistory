x = 5
x.type
x = 5
x.type()
x = 5
type(x)
x = [1, 2, 3]
x[1] = 10
print(x)
x = 5
def func():
x = 10
return x
print(func())
print(x)
[x**2 for x in range(1, 6)]
# -----------------------------------------------------------------------------
# Load libraries
# -----------------------------------------------------------------------------
library(tidymodels)
library(vroom)
# -----------------------------------------------------------------------------
# Read in data sets
# -----------------------------------------------------------------------------
train <- vroom("/Users/juneferre/fall2025/stat348/Kaggle/spooky/train.csv") |>
mutate(type = as.factor(type))
test  <- vroom("/Users/juneferre/fall2025/stat348/Kaggle/spooky/test.csv")
# Prep
test_ids <- test$id
test <- test |> select(-id)
# -----------------------------------------------------------------------------
# Recipe for multiclass classification
# -----------------------------------------------------------------------------
boo_recipe <- recipe(type ~ ., data = train) |>
step_normalize(all_numeric_predictors()) |>
step_zv(all_predictors())
# -----------------------------------------------------------------------------
# Define model
# -----------------------------------------------------------------------------
knn_spec <- nearest_neighbor(
neighbors = tune(),
weight_func = "rectangular",
dist_power = tune()
) |>
set_mode("classification") |>
set_engine("kknn")
# -----------------------------------------------------------------------------
# Cross Validation and tuning
# -----------------------------------------------------------------------------
set.seed(123)
boo_folds <- vfold_cv(train, v = 3)
boo_workflow <- workflow() |>
add_model(knn_spec) |>
add_recipe(boo_recipe)
# grid similar to Python
knn_grid <- expand.grid(
neighbors = 1:100,
dist_power = 1:10
)
boo_tune <- tune_grid(
boo_workflow,
resamples = boo_folds,
grid = knn_grid,
metrics = metric_set(accuracy)
)
best_knn <- select_best(boo_tune, "accuracy")
best_knn <- select_best(boo_tune, metric = "accuracy")
best_knn
# -----------------------------------------------------------------------------
# finalize and fit
# -----------------------------------------------------------------------------
final_knn <- finalize_workflow(boo_workflow, best_knn)
final_fit <- fit(final_knn, data = train)
preds <- predict(final_fit, test) |> pull(.pred_class)
# Make sure test has the same columns as training data used by recipe
test_clean <- test |> select(-id, everything())
View(test)
View(train)
# ==============================================================================
# Libraries
# ==============================================================================
library(tidymodels)
library(vroom)
library(doParallel)
set.seed(123)
# ==============================================================================
# Data Load
# ==============================================================================
train <- vroom("/kaggle/input/ghouls-goblins-and-ghosts-boo/train.csv.zip") |>
mutate(type = as.factor(type))
# ==============================================================================
# Data Load
# ==============================================================================
train <- vroom("/Users/juneferre/fall2025/stat348/Kaggle/spooky/train.csv") |>
mutate(type = as.factor(type))
test  <- vroom("/Users/juneferre/fall2025/stat348/Kaggle/spooky/test.csv")
# Prep
test_ids <- test$id
test <- test |> select(-id)
# ==============================================================================
# Recipe: normalize + PCA
# ==============================================================================
boo_recipe <- recipe(type ~ ., data = train) |>
step_normalize(all_numeric_predictors()) |>
step_zv(all_predictors()) |>
step_pca(all_numeric_predictors(), num_comp = tune())
# ==============================================================================
# Model: KNN with distance weighting
# ==============================================================================
knn_spec <- nearest_neighbor(
neighbors   = tune(),
weight_func = tune(),   # 'rectangular', 'triangular', 'inv', 'gaussian'
dist_power  = tune()
) |>
set_mode("classification") |>
set_engine("kknn")
# ==============================================================================
# Workflow
# ==============================================================================
boo_workflow <- workflow() |>
add_model(knn_spec) |>
add_recipe(boo_recipe)
# ==============================================================================
# Cross-validation setup
# ==============================================================================
boo_folds <- vfold_cv(train, v = 5, strata = type)
# ==============================================================================
# Grid definition (smarter search space)
# ==============================================================================
knn_grid <- grid_regular(
neighbors(range = c(3, 75)),
dist_power(range = c(1, 5)),
num_comp(range = c(5, 25)),
weight_func(values = c("rectangular", "triangular", "inv")),
levels = 6
)
# ==============================================================================
# Parallel tuning
# ==============================================================================
cl <- makeCluster(parallel::detectCores() - 1)
registerDoParallel(cl)
boo_tune <- tune_grid(
boo_workflow,
resamples = boo_folds,
grid = knn_grid,
metrics = metric_set(accuracy),
control = control_grid(save_pred = TRUE)
)
# -----------------------------------------------------------------------------
# Load libraries
# -----------------------------------------------------------------------------
library(tidymodels)
library(vroom)
# -----------------------------------------------------------------------------
# Read in data sets
# -----------------------------------------------------------------------------
train <- vroom("/Users/juneferre/fall2025/stat348/Kaggle/spooky/train.csv") |>
mutate(type = as.factor(type))
test  <- vroom("/Users/juneferre/fall2025/stat348/Kaggle/spooky/test.csv")
# Prep
test_ids <- test$id
test <- test |> select(-id)
# -----------------------------------------------------------------------------
# Recipe for multiclass classification
# -----------------------------------------------------------------------------
boo_recipe <- recipe(type ~ ., data = train) |>
step_normalize(all_numeric_predictors()) |>
step_zv(all_predictors())
# -----------------------------------------------------------------------------
# Define model
# -----------------------------------------------------------------------------
knn_spec <- nearest_neighbor(
neighbors = tune(),
weight_func = "rectangular",
dist_power = tune()
) |>
set_mode("classification") |>
set_engine("kknn")
# -----------------------------------------------------------------------------
# Cross Validation and tuning
# -----------------------------------------------------------------------------
set.seed(123)
boo_folds <- vfold_cv(train, v = 3)
boo_workflow <- workflow() |>
add_model(knn_spec) |>
add_recipe(boo_recipe)
# grid similar to Python
knn_grid <- expand.grid(
neighbors = 1:100,
dist_power = 1:10
)
boo_tune <- tune_grid(
boo_workflow,
resamples = boo_folds,
grid = knn_grid,
metrics = metric_set(accuracy)
)
View(test)
View(test)
View(test)
View(train)
best_knn <- select_best(boo_tune, metric = "accuracy")
best_knn
# -----------------------------------------------------------------------------
# finalize and fit
# -----------------------------------------------------------------------------
final_knn <- finalize_workflow(boo_workflow, best_knn)
final_fit <- fit(final_knn, data = train)
# Make sure test has the same columns as training data used by recipe
test_clean <- test |> select(-id, everything())
preds <- predict(final_fit, new_data = test_clean) |> pull(.pred_class)
preds <- predict(final_fit, new_data = test) |> pull(.pred_class)
# -----------------------------------------------------------------------------
# Load libraries
# -----------------------------------------------------------------------------
library(tidymodels)
library(vroom)
# -----------------------------------------------------------------------------
# Read in data sets
# -----------------------------------------------------------------------------
train <- vroom("/Users/juneferre/fall2025/stat348/Kaggle/spooky/train.csv") |>
mutate(type = as.factor(type))
test  <- vroom("/Users/juneferre/fall2025/stat348/Kaggle/spooky/test.csv")
# forest recipe
forest_recipe <- recipe(type ~ ., data = train_data) %>%
step_mutate_at((color), fn = factor) %>%
step_dummy(all_nominal_predictors())
# forest recipe
forest_recipe <- recipe(type ~ ., data = train) %>%
step_mutate_at((color), fn = factor) %>%
step_dummy(all_nominal_predictors())
forest_prep <- prep(forest_recipe)
forest_data <- bake(forest_prep, new_data = train_data)
forest_data <- bake(forest_prep, new_data = train)
# model
forest_lm <- rand_forest(mtry = tune(),
min_n = tune(),
trees = tune()) %>%
set_engine("ranger") %>%
set_mode("classification")
# workflow
forest_wf <- workflow() %>%
add_recipe(forest_recipe) %>% add_model(forest_lm)
# grid of tuning values
tuning_grid <- grid_random(
mtry(range = c(1, floor(sqrt(ncol(train_data))))),
min_n(range = c(2, 30)),
trees(range = c(100,200)),
size = 25)
# grid of tuning values
tuning_grid <- grid_random(
mtry(range = c(1, floor(sqrt(ncol(train))))),
min_n(range = c(2, 30)),
trees(range = c(100,200)),
size = 25)
# set up K-fold CV
folds <- vfold_cv(train, v = 5, repeats = 1, strata = type)
CV_results <- forest_wf %>%
tune_grid(
resamples = folds,
grid = tuning_grid,
metrics = metric_set(accuracy),
control = control_grid(verbose = TRUE))
# find best tuning parameters
bestTune <- CV_results %>%
select_best(metric = "accuracy")
# finalize workflow and predict
final_wf <- forest_wf %>%
finalize_workflow(bestTune) %>%
fit(data = train)
# predictions
forest_preds <- final_wf %>%
predict(new_data = test, type = "class")
forest_preds <- tibble(
id = testData$id,
type = forest_preds$.pred_class)
forest_preds <- tibble(
id = test$id,
type = forest_preds$.pred_class)
setwd("/Users/juneferre/fall2025/stat348/Kaggle/spooky/predictions")
write_csv(forest_preds, "knn1.csv")
library(tidyverse)
write_csv(forest_preds, "knn1.csv")
